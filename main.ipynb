{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from monodepth_dataloader import MonodepthDataloader\n",
    "from models import *\n",
    "\n",
    "from eval.evaluate_flow import load_gt_flow_kitti\n",
    "from eval.evaluate_mask import load_gt_mask\n",
    "from loss_utils import average_gradients\n",
    "\n",
    "from test import test\n",
    "\n",
    "# How often to record tensorboard summaries.\n",
    "SUMMARY_INTERVAL = 100\n",
    "\n",
    "# How often to run a batch through the validation model.\n",
    "VAL_INTERVAL = 2500\n",
    "\n",
    "# How often to save a model checkpoint\n",
    "SAVE_INTERVAL = 2500\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('trace', \"./\", 'directory for model checkpoints.')\n",
    "flags.DEFINE_integer('num_iterations', 300000,\n",
    "                     'number of training iterations.')\n",
    "flags.DEFINE_string('pretrained_model', '',\n",
    "                    'filepath of a pretrained model to initialize from.')\n",
    "flags.DEFINE_string(\n",
    "    'mode', '',\n",
    "    'selection from four modes of [\"flow\", \"depth\", \"depthflow\", \"stereo\"]')\n",
    "flags.DEFINE_string('train_test', 'train', 'whether to train or test')\n",
    "flags.DEFINE_boolean(\"retrain\", True, \"whether to reset the iteration counter\")\n",
    "\n",
    "flags.DEFINE_string('data_dir', '', 'root filepath of data.')\n",
    "flags.DEFINE_string('train_file',\n",
    "                    './filenames/kitti_train_files_png_4frames.txt',\n",
    "                    'training file')\n",
    "flags.DEFINE_string('gt_2012_dir', '',\n",
    "                    'directory of ground truth of kitti 2012')\n",
    "flags.DEFINE_string('gt_2015_dir', '',\n",
    "                    'directory of ground truth of kitti 2015')\n",
    "\n",
    "flags.DEFINE_integer('batch_size', 4, 'batch size for training')\n",
    "flags.DEFINE_float('learning_rate', 0.0001,\n",
    "                   'the base learning rate of the generator')\n",
    "flags.DEFINE_integer('num_gpus', 1, 'the number of gpu to use')\n",
    "\n",
    "flags.DEFINE_integer(\"img_height\", 256, \"Image height\")\n",
    "flags.DEFINE_integer(\"img_width\", 832, \"Image width\")\n",
    "\n",
    "flags.DEFINE_float(\"depth_smooth_weight\", 10.0, \"Weight for depth smoothness\")\n",
    "flags.DEFINE_float(\"ssim_weight\", 0.85,\n",
    "                   \"Weight for using ssim loss in pixel loss\")\n",
    "flags.DEFINE_float(\"flow_smooth_weight\", 10.0, \"Weight for flow smoothness\")\n",
    "flags.DEFINE_float(\"flow_consist_weight\", 0.01, \"Weight for flow consistent\")\n",
    "flags.DEFINE_float(\"flow_diff_threshold\", 4.0,\n",
    "                   \"threshold when comparing optical flow and rigid flow \")\n",
    "\n",
    "flags.DEFINE_string('eval_pose', '', 'pose seq to evaluate')\n",
    "\n",
    "FLAGS.num_scales = 4\n",
    "opt = FLAGS\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    if FLAGS.trace == \"\":\n",
    "        raise Exception(\"OUT_DIR must be specified\")\n",
    "\n",
    "    print 'Constructing models and inputs.'\n",
    "\n",
    "    if FLAGS.mode == \"depthflow\":  # stage 3: train depth and flow together\n",
    "        Model = Model_depthflow\n",
    "        Model_eval = Model_eval_depthflow\n",
    "\n",
    "        opt.eval_flow = True\n",
    "        opt.eval_depth = True\n",
    "        opt.eval_mask = True\n",
    "    elif FLAGS.mode == \"depth\":  # stage 2: train depth\n",
    "        Model = Model_depth\n",
    "        Model_eval = Model_eval_depth\n",
    "\n",
    "        opt.eval_flow = True\n",
    "        opt.eval_depth = True\n",
    "        opt.eval_mask = False\n",
    "    elif FLAGS.mode == \"flow\":  # stage 1: train flow\n",
    "        Model = Model_flow\n",
    "        Model_eval = Model_eval_flow\n",
    "\n",
    "        opt.eval_flow = True\n",
    "        opt.eval_depth = False\n",
    "        opt.eval_mask = False\n",
    "    elif FLAGS.mode == \"stereo\":\n",
    "        Model = Model_stereo\n",
    "        Model_eval = Model_eval_stereo\n",
    "\n",
    "        opt.eval_flow = False\n",
    "        opt.eval_depth = True\n",
    "        opt.eval_mask = False\n",
    "    else:\n",
    "        raise \"mode must be one of flow, depth, depthflow or stereo\"\n",
    "\n",
    "    with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        train_op = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "\n",
    "        tower_grads = []\n",
    "\n",
    "        image1, image_r, image2, image2_r, proj_cam2pix, proj_pix2cam = MonodepthDataloader(\n",
    "            FLAGS).data_batch\n",
    "\n",
    "        split_image1 = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=image1)\n",
    "        split_image2 = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=image2)\n",
    "        split_cam2pix = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=proj_cam2pix)\n",
    "        split_pix2cam = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=proj_pix2cam)\n",
    "        split_image_r = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=image_r)\n",
    "        split_image_r_next = tf.split(\n",
    "            axis=0, num_or_size_splits=FLAGS.num_gpus, value=image2_r)\n",
    "\n",
    "        summaries_cpu = tf.get_collection(tf.GraphKeys.SUMMARIES,\n",
    "                                          tf.get_variable_scope().name)\n",
    "\n",
    "        with tf.variable_scope(tf.get_variable_scope()) as vs:\n",
    "            for i in xrange(FLAGS.num_gpus):\n",
    "                with tf.device('/gpu:%d' % i):\n",
    "                    if i == FLAGS.num_gpus - 1:\n",
    "                        scopename = \"model\"\n",
    "                    else:\n",
    "                        scopename = '%s_%d' % (\"tower\", i)\n",
    "                    with tf.name_scope(scopename) as ns:\n",
    "                        if i == 0:\n",
    "                            model = Model(\n",
    "                                split_image1[i],\n",
    "                                split_image2[i],\n",
    "                                split_image_r[i],\n",
    "                                split_image_r_next[i],\n",
    "                                split_cam2pix[i],\n",
    "                                split_pix2cam[i],\n",
    "                                reuse_scope=False,\n",
    "                                scope=vs)\n",
    "                            var_pose = list(\n",
    "                                set(\n",
    "                                    tf.get_collection(\n",
    "                                        tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                        scope=\".*pose_net.*\")))\n",
    "                            var_depth = list(\n",
    "                                set(\n",
    "                                    tf.get_collection(\n",
    "                                        tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                        scope=\".*(depth_net|feature_net_disp).*\"\n",
    "                                    )))\n",
    "                            var_flow = list(\n",
    "                                set(\n",
    "                                    tf.get_collection(\n",
    "                                        tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                        scope=\".*(flow_net|feature_net_flow).*\"\n",
    "                                    )))\n",
    "\n",
    "                            if FLAGS.mode == \"depthflow\":\n",
    "                                var_train_list = var_pose + var_depth + var_flow\n",
    "                            elif FLAGS.mode == \"depth\":\n",
    "                                var_train_list = var_pose + var_depth\n",
    "                            elif FLAGS.mode == \"flow\":\n",
    "                                var_train_list = var_flow\n",
    "                            else:\n",
    "                                var_train_list = var_depth\n",
    "\n",
    "                        else:\n",
    "                            model = Model(\n",
    "                                split_image1[i],\n",
    "                                split_image2[i],\n",
    "                                split_image_r[i],\n",
    "                                split_image_r_next[i],\n",
    "                                split_cam2pix[i],\n",
    "                                split_pix2cam[i],\n",
    "                                reuse_scope=True,\n",
    "                                scope=vs)\n",
    "\n",
    "                        loss = model.loss\n",
    "                        # Retain the summaries from the final tower.\n",
    "                        if i == FLAGS.num_gpus - 1:\n",
    "                            summaries = tf.get_collection(\n",
    "                                tf.GraphKeys.SUMMARIES, ns)\n",
    "                            eval_model = Model_eval(scope=vs)\n",
    "                        # Calculate the gradients for the batch of data on this CIFAR tower.\n",
    "                        grads = train_op.compute_gradients(\n",
    "                            loss, var_list=var_train_list)\n",
    "\n",
    "                        # Keep track of the gradients across all towers.\n",
    "                        tower_grads.append(grads)\n",
    "\n",
    "        grads = average_gradients(tower_grads)\n",
    "\n",
    "        # Apply the gradients to adjust the shared variables.\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            apply_gradient_op = train_op.apply_gradients(\n",
    "                grads, global_step=global_step)\n",
    "\n",
    "        # Create a saver.\n",
    "        saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "        # Build the summary operation from the last tower summaries.\n",
    "        summary_op = tf.summary.merge(summaries + summaries_cpu)\n",
    "\n",
    "        # Make training session.\n",
    "        sess = tf.Session(config=tf.ConfigProto(\n",
    "            allow_soft_placement=True, log_device_placement=False))\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            FLAGS.trace, graph=sess.graph, flush_secs=10)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        if FLAGS.pretrained_model:\n",
    "            if FLAGS.train_test == \"test\" or (not FLAGS.retrain):\n",
    "                saver.restore(sess, FLAGS.pretrained_model)\n",
    "            elif FLAGS.mode == \"depthflow\":\n",
    "                saver_rest = tf.train.Saver(\n",
    "                    list(\n",
    "                        set(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)) -\n",
    "                        set(\n",
    "                            tf.get_collection(\n",
    "                                tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                scope=\".*(Adam_1|Adam).*\"))),\n",
    "                    max_to_keep=1)\n",
    "                saver_rest.restore(sess, FLAGS.pretrained_model)\n",
    "            elif FLAGS.mode == \"depth\":\n",
    "                saver_flow = tf.train.Saver(\n",
    "                    tf.get_collection(\n",
    "                        tf.GraphKeys.MODEL_VARIABLES,\n",
    "                        scope=\".*(flow_net|feature_net_flow).*\"),\n",
    "                    max_to_keep=1)\n",
    "                saver_flow.restore(sess, FLAGS.pretrained_model)\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    \"pretrained_model not used. Please set train_test=test or retrain=False\"\n",
    "                )\n",
    "            if FLAGS.retrain:\n",
    "                sess.run(global_step.assign(0))\n",
    "\n",
    "        start_itr = global_step.eval(session=sess)\n",
    "        tf.train.start_queue_runners(sess)\n",
    "\n",
    "        if opt.eval_flow:\n",
    "            gt_flows_2012, noc_masks_2012 = load_gt_flow_kitti(\"kitti_2012\")\n",
    "            gt_flows_2015, noc_masks_2015 = load_gt_flow_kitti(\"kitti\")\n",
    "            gt_masks = load_gt_mask()\n",
    "        else:\n",
    "            gt_flows_2012, noc_masks_2012, gt_flows_2015, noc_masks_2015, gt_masks = \\\n",
    "              None, None, None, None, None\n",
    "\n",
    "        # Run training.\n",
    "        for itr in range(start_itr, FLAGS.num_iterations):\n",
    "            if FLAGS.train_test == \"train\":\n",
    "                _, summary_str, summary_scalar_str = sess.run(\n",
    "                    [apply_gradient_op, summary_op, model.summ_op])\n",
    "\n",
    "                if (itr) % (SUMMARY_INTERVAL) == 2:\n",
    "                    summary_writer.add_summary(summary_scalar_str, itr)\n",
    "\n",
    "                if (itr) % (SUMMARY_INTERVAL * 10) == 2:\n",
    "                    summary_writer.add_summary(summary_str, itr)\n",
    "\n",
    "                if (itr) % (SAVE_INTERVAL) == 2:\n",
    "                    saver.save(\n",
    "                        sess, FLAGS.trace + '/model', global_step=global_step)\n",
    "\n",
    "            if (itr) % (VAL_INTERVAL) == 2 or FLAGS.train_test == \"test\":\n",
    "                test(sess, eval_model, itr, gt_flows_2012, noc_masks_2012,\n",
    "                     gt_flows_2015, noc_masks_2015, gt_masks)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fake_parse(self):\n",
    "        self.options = {\n",
    "            \"data_path\": os.path.join(file_dir, \"kitti_data\"),\n",
    "            \"log_dir\": os.path.join(os.path.expanduser(\"~\"), \"tmp\"),\n",
    "            \"model_name\": \"mdp\",\n",
    "            \"split\":\"eigen_zhou\",\n",
    "            \"num_layers\":18,\n",
    "            \"dataset\":\"kitti\",\n",
    "            \"png\":True,\n",
    "            \"height\":192,\n",
    "            \"width\":640,\n",
    "            \"disparity_smoothness\":1e-3,\n",
    "            \"scales\":[0, 1, 2, 3],\n",
    "            \"min_depth\":0.1,\n",
    "            \"max_depth\":100.0,\n",
    "            \"use_stereo\":False,\n",
    "            \"frame_ids\":[0, -1, 1],\n",
    "\n",
    "            # OPTIMIZATION options\n",
    "            \"batch_size\":12,\n",
    "            \"learning_rate\":1e-4,\n",
    "            \"num_epochs\":5,\n",
    "            \"scheduler_step_size\":15,\n",
    "\n",
    "            # ABLATION options\n",
    "            \"v1_multiscale\":False,\n",
    "            \"avg_reprojection\":False,\n",
    "            \"disable_automasking\":False,\n",
    "            \"predictive_mask\":False,\n",
    "            \"no_ssim\":False,\n",
    "            \"weights_init\":\"pretrained\",\n",
    "            \"pose_model_input\":\"pairs\",\n",
    "            \"pose_model_type\":\"separate_resnet\",\n",
    "\n",
    "            # SYSTEM options\n",
    "            \"no_cuda\":True,\n",
    "            \"num_workers\":12,\n",
    "\n",
    "            # LOADING options\n",
    "            \"load_weights_folder\":None,\n",
    "            \"models_to_load\":[\"encoder\", \"depth\", \"pose_encoder\", \"pose\"],\n",
    "\n",
    "            # LOGGING options\n",
    "            \"log_frequency\":250,\n",
    "            \"save_frequency\":1,\n",
    "\n",
    "            # EVALUATION options\n",
    "            \"eval_stereo\":False,\n",
    "            \"eval_mono\":False,\n",
    "            \"disable_median_scaling\":False,\n",
    "            \"pred_depth_scale_factor\":1,\n",
    "            \"ext_disp_to_eval\":None,\n",
    "            \"eval_split\":\"eigen\",\n",
    "            \"save_pred_disps\":False,\n",
    "            \"no_eval\":False,\n",
    "            \"eval_eigen_to_benchmark\":False,\n",
    "            \"eval_out_dir\":None,\n",
    "            \"post_process\":False,\n",
    "        }\n",
    "        \n",
    "        class Struct:\n",
    "            def __init__(self, **entries):\n",
    "                self.__dict__.update(entries)\n",
    "                \n",
    "        self.options = Struct(**self.options)\n",
    "        return self.options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
