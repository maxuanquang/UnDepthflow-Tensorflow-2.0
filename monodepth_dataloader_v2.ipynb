{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intrinsics(raw_cam_mat, opt, orig_height, orig_width):\n",
    "    fx = raw_cam_mat[0, 0]\n",
    "    fy = raw_cam_mat[1, 1]\n",
    "    cx = raw_cam_mat[0, 2]\n",
    "    cy = raw_cam_mat[1, 2]\n",
    "    r1 = tf.stack(\n",
    "        [fx * opt.img_width / orig_width, 0, cx * opt.img_width / orig_width])\n",
    "    r2 = tf.stack([\n",
    "        0, fy * opt.img_height / orig_height, cy * opt.img_height / orig_height\n",
    "    ])\n",
    "    r3 = tf.constant([0., 0., 1.])\n",
    "    return tf.stack([r1, r2, r3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_scale_intrinsics(raw_cam_mat, num_scales):\n",
    "    proj_cam2pix = []\n",
    "    # Scale the intrinsics accordingly for each scale\n",
    "    for s in range(num_scales):\n",
    "        fx = raw_cam_mat[0, 0] / (2**s)\n",
    "        fy = raw_cam_mat[1, 1] / (2**s)\n",
    "        cx = raw_cam_mat[0, 2] / (2**s)\n",
    "        cy = raw_cam_mat[1, 2] / (2**s)\n",
    "        r1 = tf.stack([fx, 0, cx])\n",
    "        r2 = tf.stack([0, fy, cy])\n",
    "        r3 = tf.constant([0., 0., 1.])\n",
    "        proj_cam2pix.append(tf.stack([r1, r2, r3]))\n",
    "    proj_cam2pix = tf.stack(proj_cam2pix)\n",
    "    proj_pix2cam = tf.linalg.inv(proj_cam2pix)\n",
    "    proj_cam2pix.set_shape([num_scales, 3, 3])\n",
    "    proj_pix2cam.set_shape([num_scales, 3, 3])\n",
    "    return proj_cam2pix, proj_pix2cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, get_shape=False):\n",
    "    # tf.decode_image does not return the image size, this is an ugly workaround to handle both jpeg and png\n",
    "    file_extension = image_path.split()[-1]\n",
    "    file_cond = tf.equal(file_extension, 'jpg')\n",
    "\n",
    "    image = tf.cond(\n",
    "        file_cond, lambda: tf.io.image.decode_jpeg(tf.read_file(image_path)),\n",
    "        lambda: tf.io.image.decode_png(tf.read_file(image_path)))\n",
    "    orig_height = tf.cast(tf.shape(image)[0], \"float32\")\n",
    "    orig_width = tf.cast(tf.shape(image)[1], \"float32\")\n",
    "\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_images(\n",
    "        image, [opt.img_height, opt.img_width],\n",
    "        tf.image.ResizeMethod.AREA)\n",
    "\n",
    "    if get_shape:\n",
    "        return image, orig_height, orig_width\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_pair(left_image, right_image):\n",
    "    # randomly shift gamma\n",
    "    random_gamma = tf.random.uniform([], 0.8, 1.2)\n",
    "    left_image_aug = left_image**random_gamma\n",
    "    right_image_aug = right_image**random_gamma\n",
    "\n",
    "    # randomly shift brightness\n",
    "    random_brightness = tf.random.uniform([], 0.5, 2.0)\n",
    "    left_image_aug = left_image_aug * random_brightness\n",
    "    right_image_aug = right_image_aug * random_brightness\n",
    "\n",
    "    # randomly shift color\n",
    "    random_colors = tf.random.uniform([3], 0.8, 1.2)\n",
    "    white = tf.ones([tf.shape(input=left_image)[0], tf.shape(input=left_image)[1]])\n",
    "    color_image = tf.stack(\n",
    "        [white * random_colors[i] for i in range(3)], axis=2)\n",
    "    left_image_aug *= color_image\n",
    "    right_image_aug *= color_image\n",
    "\n",
    "    # saturate\n",
    "    left_image_aug = tf.clip_by_value(left_image_aug, 0, 1)\n",
    "    right_image_aug = tf.clip_by_value(right_image_aug, 0, 1)\n",
    "\n",
    "    return left_image_aug, right_image_aug\n",
    "\n",
    "def augment_image_list(image_list):\n",
    "    # randomly shift gamma\n",
    "    random_gamma = tf.random.uniform([], 0.8, 1.2)\n",
    "    random_gamma = tf.cast(random_gamma, tf.float32)\n",
    "    image_list = [img**random_gamma for img in image_list]\n",
    "\n",
    "    # randomly shift brightness\n",
    "    random_brightness = tf.random.uniform([], 0.5, 2.0)\n",
    "    random_brightness = tf.cast(random_brightness, tf.float32)\n",
    "    image_list = [img * random_brightness for img in image_list]\n",
    "\n",
    "    # randomly shift color\n",
    "    random_colors = tf.random.uniform([3], 0.8, 1.2)\n",
    "    white = tf.ones(\n",
    "        [tf.shape(input=image_list[0])[0], tf.shape(input=image_list[0])[1]])\n",
    "    color_image = tf.stack(\n",
    "        [white * random_colors[i] for i in range(3)], axis=2)\n",
    "    image_list = [img * color_image for img in image_list]\n",
    "\n",
    "    # saturate\n",
    "    image_list = [tf.clip_by_value(img, 0, 1) for img in image_list]\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def make_intrinsics_matrix(fx, fy, cx, cy):\n",
    "    # Assumes batch input\n",
    "    batch_size = fx.get_shape().as_list()[0]\n",
    "    zeros = tf.zeros_like(fx)\n",
    "    r1 = tf.stack([fx, zeros, cx], axis=1)\n",
    "    r2 = tf.stack([zeros, fy, cy], axis=1)\n",
    "    r3 = tf.constant([0., 0., 1.], shape=[1, 3])\n",
    "    r3 = tf.tile(r3, [batch_size, 1])\n",
    "    intrinsics = tf.stack([r1, r2, r3], axis=1)\n",
    "    return intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(im, intrinsics, out_h, out_w):\n",
    "    # Random scaling\n",
    "    def random_scaling(im, intrinsics):\n",
    "        batch_size, in_h, in_w, _ = im.get_shape().as_list()\n",
    "        scaling = tf.random.uniform([2], 1, 1.15)\n",
    "        x_scaling = scaling[0]\n",
    "        y_scaling = scaling[1]\n",
    "        out_h = tf.cast(in_h * y_scaling, dtype=tf.int32)\n",
    "        out_w = tf.cast(in_w * x_scaling, dtype=tf.int32)\n",
    "        im = tf.compat.v1.image.resize(im, [out_h, out_w], method=tf.image.ResizeMethod.AREA)\n",
    "        fx = intrinsics[:, 0, 0] * x_scaling\n",
    "        fy = intrinsics[:, 1, 1] * y_scaling\n",
    "        cx = intrinsics[:, 0, 2] * x_scaling\n",
    "        cy = intrinsics[:, 1, 2] * y_scaling\n",
    "        intrinsics = make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "        return im, intrinsics\n",
    "\n",
    "    # Random cropping\n",
    "    def random_cropping(im, intrinsics, out_h, out_w):\n",
    "        # batch_size, in_h, in_w, _ = im.get_shape().as_list()\n",
    "        batch_size, in_h, in_w, _ = tf.unstack(tf.shape(input=im))\n",
    "        offset_y = tf.random.uniform(\n",
    "            [1], 0, in_h - out_h + 1, dtype=tf.int32)[0]\n",
    "        offset_x = tf.random.uniform(\n",
    "            [1], 0, in_w - out_w + 1, dtype=tf.int32)[0]\n",
    "        im = tf.image.crop_to_bounding_box(im, offset_y, offset_x, out_h,\n",
    "                                           out_w)\n",
    "        fx = intrinsics[:, 0, 0]\n",
    "        fy = intrinsics[:, 1, 1]\n",
    "        cx = intrinsics[:, 0, 2] - tf.cast(offset_x, dtype=tf.float32)\n",
    "        cy = intrinsics[:, 1, 2] - tf.cast(offset_y, dtype=tf.float32)\n",
    "        intrinsics = make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "        return im, intrinsics\n",
    "\n",
    "    im, intrinsics = random_scaling(im, intrinsics)\n",
    "    im, intrinsics = random_cropping(im, intrinsics, out_h, out_w)\n",
    "    return im, intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train(opt):\n",
    "    filenames_file = opt.train_file\n",
    "    data_path = opt.data_dir\n",
    "\n",
    "    with open(filenames_file, 'r') as f:\n",
    "        input_queue = f.readlines()\n",
    "    split_line = [line.split() for line in input_queue]\n",
    "    \n",
    "    for line in split_line:\n",
    "        left_image_path = r\"/\".join([data_path, line[0]])\n",
    "        right_image_path = r\"/\".join([data_path, line[1]])\n",
    "        next_left_image_path = r\"/\".join([data_path, line[2]])\n",
    "        next_right_image_path = r\"/\".join([data_path, line[3]])\n",
    "        cam_intrinsic_path = r\"/\".join([data_path, line[4]])\n",
    "        \n",
    "        left_image_o = cv2.imread(left_image_path)\n",
    "        left_image_o = cv2.resize(left_image_o, (opt.img_width, opt.img_height))\n",
    "        orig_height, orig_width = left_image_o.shape[:2]\n",
    "        right_image_o = cv2.imread(right_image_path)\n",
    "        right_image_o = cv2.resize(right_image_o, (opt.img_width, opt.img_height))\n",
    "        next_left_image_o = cv2.imread(next_left_image_path)\n",
    "        next_left_image_o = cv2.resize(next_left_image_o, (opt.img_width, opt.img_height))\n",
    "        next_right_image_o = cv2.imread(next_right_image_path)\n",
    "        next_right_image_o = cv2.resize(next_right_image_o, (opt.img_width, opt.img_height))\n",
    "        \n",
    "        # randomly flip images\n",
    "        do_flip = tf.random.uniform([], 0, 1)\n",
    "        left_image = tf.cond(pred=do_flip > 0.5,\n",
    "                             true_fn=lambda: tf.compat.v1.image.flip_left_right(right_image_o),\n",
    "                             false_fn=lambda: left_image_o)\n",
    "        right_image = tf.cond(pred=do_flip > 0.5,\n",
    "                              true_fn=lambda: tf.compat.v1.image.flip_left_right(left_image_o),\n",
    "                              false_fn=lambda: right_image_o)\n",
    "        \n",
    "        next_left_image = tf.cond(\n",
    "            pred=do_flip > 0.5,\n",
    "            true_fn=lambda: tf.compat.v1.image.flip_left_right(next_right_image_o),\n",
    "            false_fn=lambda: next_left_image_o)\n",
    "        next_right_image = tf.cond(\n",
    "            pred=do_flip > 0.5, true_fn=lambda: tf.compat.v1.image.flip_left_right(next_left_image_o),\n",
    "            false_fn=lambda: next_right_image_o)\n",
    "        \n",
    "        # random shuffle order of image\n",
    "        do_flip_fb = tf.random.uniform([], 0, 1)\n",
    "        left_image, right_image, next_left_image, next_right_image = tf.cond(\n",
    "            pred=do_flip_fb > 0.5,\n",
    "            true_fn=lambda: (next_left_image, next_right_image, left_image, right_image),\n",
    "            false_fn=lambda: (left_image, right_image, next_left_image, next_right_image)\n",
    "        )\n",
    "        \n",
    "        #randomly augment images\n",
    "#         do_augment  = tf.random.uniform([], 0, 1)\n",
    "#         image_list = [left_image, right_image, next_left_image, next_right_image]\n",
    "#         left_image, right_image, next_left_image, next_right_image = tf.cond(do_augment > 0.5, \n",
    "#                                                                              lambda: augment_image_list(image_list), \n",
    "#                                                                              lambda: image_list)\n",
    "\n",
    "        # calculate raw camera matrix\n",
    "        raw_cam_contents = tf.io.read_file(cam_intrinsic_path)\n",
    "        last_line = tf.compat.v1.string_split(\n",
    "            [raw_cam_contents], delimiter=\"\\n\").values[-1]\n",
    "        raw_cam_vec = tf.compat.v1.strings.to_number(\n",
    "            tf.compat.v1.string_split([last_line]).values[1:])\n",
    "        raw_cam_mat = tf.reshape(raw_cam_vec, [3, 4])\n",
    "        raw_cam_mat = raw_cam_mat[0:3, 0:3]\n",
    "        raw_cam_mat = rescale_intrinsics(raw_cam_mat, opt, orig_height,\n",
    "                                         orig_width)\n",
    "\n",
    "        # Scale and crop augmentation\n",
    "#         im_batch = tf.concat([tf.expand_dims(left_image, 0), \n",
    "#                          tf.expand_dims(right_image, 0),\n",
    "#                          tf.expand_dims(next_left_image, 0),\n",
    "#                          tf.expand_dims(next_right_image, 0)], axis=3)\n",
    "#         raw_cam_mat_batch = tf.expand_dims(raw_cam_mat, axis=0)\n",
    "#         im_batch, raw_cam_mat_batch = data_augmentation(im_batch, raw_cam_mat_batch, opt.img_height, opt.img_width)\n",
    "#         left_image, right_image, next_left_image, next_right_image = tf.split(im_batch[0,:,:,:], num_or_size_splits=4, axis=2)\n",
    "#         raw_cam_mat = raw_cam_mat_batch[0,:,:]\n",
    "        \n",
    "        # calculate projection\n",
    "        proj_cam2pix, proj_pix2cam = get_multi_scale_intrinsics(raw_cam_mat,\n",
    "                                                                opt.num_scales)\n",
    "\n",
    "        yield left_image, right_image, next_left_image, next_right_image, proj_cam2pix, proj_pix2cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_parse import fake_parse\n",
    "opt = fake_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator_train(opt),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,None,3), dtype=tf.float32),\n",
    "    ))\n",
    "my_dataset = my_dataset.batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 4, 3, 3)\n",
      "(4, 4, 3, 3)\n",
      "______________\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 4, 3, 3)\n",
      "(4, 4, 3, 3)\n",
      "______________\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 256, 832, 3)\n",
      "(4, 4, 3, 3)\n",
      "(4, 4, 3, 3)\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "for element in my_dataset:\n",
    "    left_image_o, right_image_o, next_left_image_o, next_right_image_o, proj_cam2pix, proj_pix2cam = element\n",
    "    print(left_image_o.shape)\n",
    "    print(right_image_o.shape)\n",
    "    print(next_right_image_o.shape)\n",
    "    print(next_left_image_o.shape)\n",
    "    print(proj_cam2pix.shape)\n",
    "    print(proj_pix2cam.shape)\n",
    "    print('______________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
