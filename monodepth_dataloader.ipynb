{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_length_tf(t):\n",
    "    return tf.compat.v1.py_func(len, [t], [tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intrinsics(raw_cam_mat, opt, orig_height, orig_width):\n",
    "    fx = raw_cam_mat[0, 0]\n",
    "    fy = raw_cam_mat[1, 1]\n",
    "    cx = raw_cam_mat[0, 2]\n",
    "    cy = raw_cam_mat[1, 2]\n",
    "    r1 = tf.stack(\n",
    "        [fx * opt.img_width / orig_width, 0, cx * opt.img_width / orig_width])\n",
    "    r2 = tf.stack([\n",
    "        0, fy * opt.img_height / orig_height, cy * opt.img_height / orig_height\n",
    "    ])\n",
    "    r3 = tf.constant([0., 0., 1.])\n",
    "    return tf.stack([r1, r2, r3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_scale_intrinsics(raw_cam_mat, num_scales):\n",
    "    proj_cam2pix = []\n",
    "    # Scale the intrinsics accordingly for each scale\n",
    "    for s in range(num_scales):\n",
    "        fx = raw_cam_mat[0, 0] / (2**s)\n",
    "        fy = raw_cam_mat[1, 1] / (2**s)\n",
    "        cx = raw_cam_mat[0, 2] / (2**s)\n",
    "        cy = raw_cam_mat[1, 2] / (2**s)\n",
    "        r1 = tf.stack([fx, 0, cx])\n",
    "        r2 = tf.stack([0, fy, cy])\n",
    "        r3 = tf.constant([0., 0., 1.])\n",
    "        proj_cam2pix.append(tf.stack([r1, r2, r3]))\n",
    "    proj_cam2pix = tf.stack(proj_cam2pix)\n",
    "    proj_pix2cam = tf.linalg.inv(proj_cam2pix)\n",
    "    proj_cam2pix.set_shape([num_scales, 3, 3])\n",
    "    proj_pix2cam.set_shape([num_scales, 3, 3])\n",
    "    return proj_cam2pix, proj_pix2cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_intrinsics_matrix(fx, fy, cx, cy):\n",
    "    # Assumes batch input\n",
    "    batch_size = fx.get_shape().as_list()[0]\n",
    "    zeros = tf.zeros_like(fx)\n",
    "    r1 = tf.stack([fx, zeros, cx], axis=1)\n",
    "    r2 = tf.stack([zeros, fy, cy], axis=1)\n",
    "    r3 = tf.constant([0., 0., 1.], shape=[1, 3])\n",
    "    r3 = tf.tile(r3, [batch_size, 1])\n",
    "    intrinsics = tf.stack([r1, r2, r3], axis=1)\n",
    "    return intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(im, intrinsics, out_h, out_w):\n",
    "    # Random scaling\n",
    "    def random_scaling(im, intrinsics):\n",
    "        batch_size, in_h, in_w, _ = im.get_shape().as_list()\n",
    "        scaling = tf.random.uniform([2], 1, 1.15)\n",
    "        x_scaling = scaling[0]\n",
    "        y_scaling = scaling[1]\n",
    "        out_h = tf.cast(in_h * y_scaling, dtype=tf.int32)\n",
    "        out_w = tf.cast(in_w * x_scaling, dtype=tf.int32)\n",
    "        im = tf.compat.v1.image.resize(im, [out_h, out_w], method=tf.compat.v1.image.ResizeMethod.AREA)\n",
    "        fx = intrinsics[:, 0, 0] * x_scaling\n",
    "        fy = intrinsics[:, 1, 1] * y_scaling\n",
    "        cx = intrinsics[:, 0, 2] * x_scaling\n",
    "        cy = intrinsics[:, 1, 2] * y_scaling\n",
    "        intrinsics = make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "        return im, intrinsics\n",
    "\n",
    "    # Random cropping\n",
    "    def random_cropping(im, intrinsics, out_h, out_w):\n",
    "        # batch_size, in_h, in_w, _ = im.get_shape().as_list()\n",
    "        batch_size, in_h, in_w, _ = tf.unstack(tf.shape(input=im))\n",
    "        offset_y = tf.random.uniform(\n",
    "            [1], 0, in_h - out_h + 1, dtype=tf.int32)[0]\n",
    "        offset_x = tf.random.uniform(\n",
    "            [1], 0, in_w - out_w + 1, dtype=tf.int32)[0]\n",
    "        im = tf.image.crop_to_bounding_box(im, offset_y, offset_x, out_h,\n",
    "                                           out_w)\n",
    "        fx = intrinsics[:, 0, 0]\n",
    "        fy = intrinsics[:, 1, 1]\n",
    "        cx = intrinsics[:, 0, 2] - tf.cast(offset_x, dtype=tf.float32)\n",
    "        cy = intrinsics[:, 1, 2] - tf.cast(offset_y, dtype=tf.float32)\n",
    "        intrinsics = make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "        return im, intrinsics\n",
    "\n",
    "    im, intrinsics = random_scaling(im, intrinsics)\n",
    "    im, intrinsics = random_cropping(im, intrinsics, out_h, out_w)\n",
    "    return im, intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonodepthDataloader(object):\n",
    "    \"\"\"monodepth dataloader\"\"\"\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        self.data_path = opt.data_dir\n",
    "        self.opt = opt\n",
    "        filenames_file = opt.train_file\n",
    "        \n",
    "        with open(filenames_file, 'r') as f:\n",
    "            input_queue = f.readlines()\n",
    "        split_line = [line.split() for line in input_queue[:-1]]\n",
    "\n",
    "        # we load only one image for test, except if we trained a stereo model   \n",
    "        left_image_path = [r\"/\".join([data_path, split_line[i][0]]) for i in range(len(split_line))]\n",
    "        right_image_path = [r\"/\".join([data_path, split_line[i][1]]) for i in range(len(split_line))] \n",
    "        next_left_image_path = [r\"/\".join([data_path, split_line[i][2]]) for i in range(len(split_line))]\n",
    "        next_right_image_path = [r\"/\".join([data_path, split_line[i][3]]) for i in range(len(split_line))]\n",
    "        cam_intrinsic_path = [r\"/\".join([data_path, split_line[i][4]]) for i in range(len(split_line))]\n",
    "        \n",
    "        # read image\n",
    "        left_image_o, orig_height, orig_width = self.read_image(\n",
    "            left_image_path, get_shape=True)\n",
    "        right_image_o = self.read_image(right_image_path)\n",
    "        next_left_image_o = self.read_image(next_left_image_path)\n",
    "        next_right_image_o = self.read_image(next_right_image_path)\n",
    "\n",
    "        # randomly flip images\n",
    "        do_flip = tf.random.uniform([], 0, 1)\n",
    "        left_image = tf.cond(pred=do_flip > 0.5,\n",
    "                             true_fn=lambda: tf.image.flip_left_right(right_image_o),\n",
    "                             false_fn=lambda: left_image_o)\n",
    "        right_image = tf.cond(pred=do_flip > 0.5,\n",
    "                              true_fn=lambda: tf.image.flip_left_right(left_image_o),\n",
    "                              false_fn=lambda: right_image_o)\n",
    "\n",
    "        next_left_image = tf.cond(\n",
    "            pred=do_flip > 0.5,\n",
    "            true_fn=lambda: tf.image.flip_left_right(next_right_image_o),\n",
    "            false_fn=lambda: next_left_image_o)\n",
    "        next_right_image = tf.cond(\n",
    "            pred=do_flip > 0.5, true_fn=lambda: tf.image.flip_left_right(next_left_image_o),\n",
    "            false_fn=lambda: next_right_image_o)\n",
    "\n",
    "        do_flip_fb = tf.random.uniform([], 0, 1)\n",
    "        left_image, right_image, next_left_image, next_right_image = tf.cond(\n",
    "            pred=do_flip_fb > 0.5,\n",
    "            true_fn=lambda: (next_left_image, next_right_image, left_image, right_image),\n",
    "            false_fn=lambda: (left_image, right_image, next_left_image, next_right_image)\n",
    "        )\n",
    "\n",
    "        # randomly augment images\n",
    "        #         do_augment  = tf.random_uniform([], 0, 0)\n",
    "        #         image_list = [left_image, right_image, next_left_image, next_right_image]\n",
    "        #         left_image, right_image, next_left_image, next_right_image = tf.cond(do_augment > 0.5, \n",
    "        #                                                                              lambda: self.augment_image_list(image_list), \n",
    "        #                                                                              lambda: image_list)\n",
    "\n",
    "        left_image.set_shape([None, None, 3])\n",
    "        right_image.set_shape([None, None, 3])\n",
    "        next_left_image.set_shape([None, None, 3])\n",
    "        next_right_image.set_shape([None, None, 3])\n",
    "\n",
    "        raw_cam_contents = tf.io.read_file(cam_intrinsic_path)\n",
    "        last_line = tf.compat.v1.string_split(\n",
    "            [raw_cam_contents], delimiter=\"\\n\").values[-1]\n",
    "        raw_cam_vec = tf.strings.to_number(\n",
    "            tf.compat.v1.string_split([last_line]).values[1:])\n",
    "        raw_cam_mat = tf.reshape(raw_cam_vec, [3, 4])\n",
    "        raw_cam_mat = raw_cam_mat[0:3, 0:3]\n",
    "        raw_cam_mat = rescale_intrinsics(raw_cam_mat, opt, orig_height,\n",
    "                                         orig_width)\n",
    "\n",
    "        # Scale and crop augmentation\n",
    "        #         im_batch = tf.concat([tf.expand_dims(left_image, 0), \n",
    "        #                          tf.expand_dims(right_image, 0),\n",
    "        #                          tf.expand_dims(next_left_image, 0),\n",
    "        #                          tf.expand_dims(next_right_image, 0)], axis=3)\n",
    "        #         raw_cam_mat_batch = tf.expand_dims(raw_cam_mat, axis=0)\n",
    "        #         im_batch, raw_cam_mat_batch = data_augmentation(im_batch, raw_cam_mat_batch, self.opt.img_height, self.opt.img_width)\n",
    "        #         left_image, right_image, next_left_image, next_right_image = tf.split(im_batch[0,:,:,:], num_or_size_splits=4, axis=2)\n",
    "        #         raw_cam_mat = raw_cam_mat_batch[0,:,:]\n",
    "\n",
    "        proj_cam2pix, proj_pix2cam = get_multi_scale_intrinsics(raw_cam_mat,\n",
    "                                                                opt.num_scales)\n",
    "\n",
    "        # capacity = min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "        min_after_dequeue = 2048\n",
    "        capacity = min_after_dequeue + 4 * opt.batch_size\n",
    "        self.data_batch = tf.compat.v1.train.shuffle_batch([\n",
    "            left_image, right_image, next_left_image, next_right_image,\n",
    "            proj_cam2pix, proj_pix2cam\n",
    "        ], opt.batch_size, capacity, min_after_dequeue, 10)\n",
    "\n",
    "    def augment_image_pair(self, left_image, right_image):\n",
    "        # randomly shift gamma\n",
    "        random_gamma = tf.random.uniform([], 0.8, 1.2)\n",
    "        left_image_aug = left_image**random_gamma\n",
    "        right_image_aug = right_image**random_gamma\n",
    "\n",
    "        # randomly shift brightness\n",
    "        random_brightness = tf.random.uniform([], 0.5, 2.0)\n",
    "        left_image_aug = left_image_aug * random_brightness\n",
    "        right_image_aug = right_image_aug * random_brightness\n",
    "\n",
    "        # randomly shift color\n",
    "        random_colors = tf.random.uniform([3], 0.8, 1.2)\n",
    "        white = tf.ones([tf.shape(input=left_image)[0], tf.shape(input=left_image)[1]])\n",
    "        color_image = tf.stack(\n",
    "            [white * random_colors[i] for i in range(3)], axis=2)\n",
    "        left_image_aug *= color_image\n",
    "        right_image_aug *= color_image\n",
    "\n",
    "        # saturate\n",
    "        left_image_aug = tf.clip_by_value(left_image_aug, 0, 1)\n",
    "        right_image_aug = tf.clip_by_value(right_image_aug, 0, 1)\n",
    "\n",
    "        return left_image_aug, right_image_aug\n",
    "\n",
    "    def augment_image_list(self, image_list):\n",
    "        # randomly shift gamma\n",
    "        random_gamma = tf.random.uniform([], 0.8, 1.2)\n",
    "        image_list = [img**random_gamma for img in image_list]\n",
    "\n",
    "        # randomly shift brightness\n",
    "        random_brightness = tf.random.uniform([], 0.5, 2.0)\n",
    "        image_list = [img * random_brightness for img in image_list]\n",
    "\n",
    "        # randomly shift color\n",
    "        random_colors = tf.random.uniform([3], 0.8, 1.2)\n",
    "        white = tf.ones(\n",
    "            [tf.shape(input=image_list[0])[0], tf.shape(input=image_list[0])[1]])\n",
    "        color_image = tf.stack(\n",
    "            [white * random_colors[i] for i in range(3)], axis=2)\n",
    "        image_list = [img * color_image for img in image_list]\n",
    "\n",
    "        # saturate\n",
    "        image_list = [tf.clip_by_value(img, 0, 1) for img in image_list]\n",
    "\n",
    "        return image_list\n",
    "\n",
    "    def read_image(self, image_path, get_shape=False):\n",
    "#         left_image_o, orig_height, orig_width = self.read_image(\n",
    "#             left_image_path, get_shape=True)\n",
    "        # tf.decode_image does not return the image size, this is an ugly workaround to handle both jpeg and png\n",
    "        path_length = len(image_path)\n",
    "        file_extension = image_path[0].split(\".\")[-1]\n",
    "        \n",
    "        if file_extension == \"jpg\":\n",
    "            image = tf.image.decode_jpeg(tf.io.read_file(image_path))\n",
    "        else:\n",
    "            image = tf.image.decode_png(tf.io.read_file(image_path))\n",
    "\n",
    "        orig_height = tf.cast(tf.shape(input=image)[0], \"float32\")\n",
    "        orig_width = tf.cast(tf.shape(input=image)[1], \"float32\")\n",
    "\n",
    "        image = tf.compat.v1.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.compat.v1.image.resize(\n",
    "            image, [self.opt.img_height, self.opt.img_width],\n",
    "            tf.compat.v1.image.ResizeMethod.AREA)\n",
    "\n",
    "        if get_shape:\n",
    "            return image, orig_height, orig_width\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1523b3a9072b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfilenames_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minput_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "filenames_file = opt.train_file\n",
    "data_path = opt.data_dir\n",
    "\n",
    "with open(filenames_file, 'r') as f:\n",
    "    input_queue = f.readlines()\n",
    "split_line = [line.split() for line in input_queue[:-1]]\n",
    "\n",
    "# we load only one image for test, except if we trained a stereo model   \n",
    "left_image_path = [r\"/\".join([data_path, split_line[i][0]]) for i in range(len(split_line))]\n",
    "right_image_path = [r\"/\".join([data_path, split_line[i][1]]) for i in range(len(split_line))] \n",
    "next_left_image_path = [r\"/\".join([data_path, split_line[i][2]]) for i in range(len(split_line))]\n",
    "next_right_image_path = [r\"/\".join([data_path, split_line[i][3]]) for i in range(len(split_line))]\n",
    "cam_intrinsic_path = [r\"/\".join([data_path, split_line[i][4]]) for i in range(len(split_line))]\n",
    "\n",
    "print(left_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = MonodepthDataloader(opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
