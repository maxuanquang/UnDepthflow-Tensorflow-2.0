{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\quangmx\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from optical_flow_warp_old import transformer_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.uniform(\n",
    "    (4,123,123,3), minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None\n",
    ")\n",
    "\n",
    "d = tf.random.uniform(\n",
    "    (4,123,123,3), minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_like(inputs, ref):\n",
    "    iH, iW = inputs.get_shape()[1], inputs.get_shape()[2]\n",
    "    rH, rW = ref.get_shape()[1], ref.get_shape()[2]\n",
    "    if iH == rH and iW == rW:\n",
    "        return inputs\n",
    "    return tf.image.resize_bilinear(inputs, [rH.value, rW.value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(_x, alpha=0.1):\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alpha * (_x - abs(_x)) * 0.5\n",
    "\n",
    "    return pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_pyramid_flow(image, reuse):\n",
    "    with tf.variable_scope('feature_net_flow'):\n",
    "        with slim.arg_scope(\n",
    "            [slim.conv2d, slim.conv2d_transpose],\n",
    "                weights_regularizer=slim.l2_regularizer(0.0004),\n",
    "                activation_fn=leaky_relu,\n",
    "                variables_collections=[\"flownet\"],\n",
    "                reuse=reuse):\n",
    "            cnv1 = slim.conv2d(image, 16, [3, 3], stride=2, scope=\"cnv1\")\n",
    "            cnv2 = slim.conv2d(cnv1, 16, [3, 3], stride=1, scope=\"cnv2\")\n",
    "            cnv3 = slim.conv2d(cnv2, 32, [3, 3], stride=2, scope=\"cnv3\")\n",
    "            cnv4 = slim.conv2d(cnv3, 32, [3, 3], stride=1, scope=\"cnv4\")\n",
    "            cnv5 = slim.conv2d(cnv4, 64, [3, 3], stride=2, scope=\"cnv5\")\n",
    "            cnv6 = slim.conv2d(cnv5, 64, [3, 3], stride=1, scope=\"cnv6\")\n",
    "            cnv7 = slim.conv2d(cnv6, 96, [3, 3], stride=2, scope=\"cnv7\")\n",
    "            cnv8 = slim.conv2d(cnv7, 96, [3, 3], stride=1, scope=\"cnv8\")\n",
    "            cnv9 = slim.conv2d(cnv8, 128, [3, 3], stride=2, scope=\"cnv9\")\n",
    "            cnv10 = slim.conv2d(cnv9, 128, [3, 3], stride=1, scope=\"cnv10\")\n",
    "            cnv11 = slim.conv2d(cnv10, 192, [3, 3], stride=2, scope=\"cnv11\")\n",
    "            cnv12 = slim.conv2d(cnv11, 192, [3, 3], stride=1, scope=\"cnv12\")\n",
    "\n",
    "            return cnv2, cnv4, cnv6, cnv8, cnv10, cnv12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_volumn(feature1, feature2, d=4):\n",
    "    batch_size, H, W, feature_num = map(int, feature1.get_shape()[0:4])\n",
    "    feature2 = tf.pad(feature2, [[0, 0], [d, d], [d, d], [0, 0]], \"CONSTANT\")\n",
    "    cv = []\n",
    "    for i in range(2 * d + 1):\n",
    "        for j in range(2 * d + 1):\n",
    "            cv.append(\n",
    "                tf.reduce_mean(\n",
    "                    feature1 * feature2[:, i:(i + H), j:(j + W), :],\n",
    "                    axis=3,\n",
    "                    keep_dims=True))\n",
    "    return tf.concat(cv, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow_decoder_dc(inputs, level):\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.conv2d_transpose],\n",
    "            weights_regularizer=slim.l2_regularizer(0.0004),\n",
    "            activation_fn=leaky_relu):\n",
    "        cnv1 = slim.conv2d(\n",
    "            inputs, 128, [3, 3], stride=1, scope=\"cnv1_fd_\" + str(level))\n",
    "        cnv2 = slim.conv2d(\n",
    "            cnv1, 128, [3, 3], stride=1, scope=\"cnv2_fd_\" + str(level))\n",
    "        cnv3 = slim.conv2d(\n",
    "            tf.concat(\n",
    "                [cnv1, cnv2], axis=3),\n",
    "            96, [3, 3],\n",
    "            stride=1,\n",
    "            scope=\"cnv3_fd_\" + str(level))\n",
    "        cnv4 = slim.conv2d(\n",
    "            tf.concat(\n",
    "                [cnv2, cnv3], axis=3),\n",
    "            64, [3, 3],\n",
    "            stride=1,\n",
    "            scope=\"cnv4_fd_\" + str(level))\n",
    "        cnv5 = slim.conv2d(\n",
    "            tf.concat(\n",
    "                [cnv3, cnv4], axis=3),\n",
    "            32, [3, 3],\n",
    "            stride=1,\n",
    "            scope=\"cnv5_fd_\" + str(level))\n",
    "        flow = slim.conv2d(\n",
    "            tf.concat(\n",
    "                [cnv4, cnv5], axis=3),\n",
    "            2, [3, 3],\n",
    "            stride=1,\n",
    "            scope=\"cnv6_fd_\" + str(level),\n",
    "            activation_fn=None)\n",
    "\n",
    "        return flow, cnv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_net(inputs):\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.conv2d_transpose],\n",
    "            weights_regularizer=slim.l2_regularizer(0.0004),\n",
    "            activation_fn=leaky_relu):\n",
    "        cnv1 = slim.conv2d(inputs, 128, [3, 3], rate=1, scope=\"cnv1_cn\")\n",
    "        cnv2 = slim.conv2d(cnv1, 128, [3, 3], rate=2, scope=\"cnv2_cn\")\n",
    "        cnv3 = slim.conv2d(cnv2, 128, [3, 3], rate=4, scope=\"cnv3_cn\")\n",
    "        cnv4 = slim.conv2d(cnv3, 96, [3, 3], rate=8, scope=\"cnv4_cn\")\n",
    "        cnv5 = slim.conv2d(cnv4, 64, [3, 3], rate=16, scope=\"cnv5_cn\")\n",
    "        cnv6 = slim.conv2d(cnv5, 32, [3, 3], rate=1, scope=\"cnv6_cn\")\n",
    "\n",
    "        flow = slim.conv2d(\n",
    "            cnv6, 2, [3, 3], rate=1, scope=\"cnv7_cn\", activation_fn=None)\n",
    "        return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model_pwc_full(image1, image2, feature1, feature2):\n",
    "    with tf.variable_scope('flow_net'):\n",
    "        batch_size, H, W, color_channels = map(int, image1.get_shape()[0:4])\n",
    "\n",
    "        #############################\n",
    "        feature1_1, feature1_2, feature1_3, feature1_4, feature1_5, feature1_6 = feature1\n",
    "        feature2_1, feature2_2, feature2_3, feature2_4, feature2_5, feature2_6 = feature2\n",
    "\n",
    "        cv6 = cost_volumn(feature1_6, feature2_6, d=4)\n",
    "        flow6, _ = optical_flow_decoder_dc(cv6, level=6)\n",
    "\n",
    "        flow6to5 = tf.image.resize_bilinear(flow6,\n",
    "                                            [H / (2**5), (W / (2**5))]) * 2.0\n",
    "        feature2_5w = transformer_old(feature2_5, flow6to5, [H / 32, W / 32])\n",
    "        cv5 = cost_volumn(feature1_5, feature2_5w, d=4)\n",
    "        flow5, _ = optical_flow_decoder_dc(\n",
    "            tf.concat(\n",
    "                [cv5, feature1_5, flow6to5], axis=3), level=5)\n",
    "        flow5 = flow5 + flow6to5\n",
    "\n",
    "        flow5to4 = tf.image.resize_bilinear(flow5,\n",
    "                                            [H / (2**4), (W / (2**4))]) * 2.0\n",
    "        feature2_4w = transformer_old(feature2_4, flow5to4, [H / 16, W / 16])\n",
    "        cv4 = cost_volumn(feature1_4, feature2_4w, d=4)\n",
    "        flow4, _ = optical_flow_decoder_dc(\n",
    "            tf.concat(\n",
    "                [cv4, feature1_4, flow5to4], axis=3), level=4)\n",
    "        flow4 = flow4 + flow5to4\n",
    "\n",
    "        flow4to3 = tf.image.resize_bilinear(flow4,\n",
    "                                            [H / (2**3), (W / (2**3))]) * 2.0\n",
    "        feature2_3w = transformer_old(feature2_3, flow4to3, [H / 8, W / 8])\n",
    "        cv3 = cost_volumn(feature1_3, feature2_3w, d=4)\n",
    "        flow3, _ = optical_flow_decoder_dc(\n",
    "            tf.concat(\n",
    "                [cv3, feature1_3, flow4to3], axis=3), level=3)\n",
    "        flow3 = flow3 + flow4to3\n",
    "\n",
    "        flow3to2 = tf.image.resize_bilinear(flow3,\n",
    "                                            [H / (2**2), (W / (2**2))]) * 2.0\n",
    "        feature2_2w = transformer_old(feature2_2, flow3to2, [H / 4, W / 4])\n",
    "        cv2 = cost_volumn(feature1_2, feature2_2w, d=4)\n",
    "        flow2_raw, f2 = optical_flow_decoder_dc(\n",
    "            tf.concat(\n",
    "                [cv2, feature1_2, flow3to2], axis=3), level=2)\n",
    "        flow2_raw = flow2_raw + flow3to2\n",
    "\n",
    "        flow2 = context_net(tf.concat([flow2_raw, f2], axis=3)) + flow2_raw\n",
    "\n",
    "        flow0_enlarge = tf.image.resize_bilinear(flow2 * 4.0, [H, W])\n",
    "        flow1_enlarge = tf.image.resize_bilinear(flow3 * 4.0, [H // 2, W // 2])\n",
    "        flow2_enlarge = tf.image.resize_bilinear(flow4 * 4.0, [H // 4, W // 4])\n",
    "        flow3_enlarge = tf.image.resize_bilinear(flow5 * 4.0, [H // 8, W // 8])\n",
    "\n",
    "        return flow0_enlarge, flow1_enlarge, flow2_enlarge, flow3_enlarge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
